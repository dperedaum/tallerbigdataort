{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21352d0f-e692-4083-ad42-87ce65912b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18T21:53:11,471 WARN [Thread-4] org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2023-11-18T21:53:12,940 WARN [Thread-4] org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "2023-11-18T21:53:12,941 WARN [Thread-4] org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"crear_tablas_hive\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca96ac8e-a39e-420b-8457-a3324d6f41ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18T21:59:24,672 INFO [Thread-4] org.apache.hadoop.hive.conf.HiveConf - Found configuration file file:/home/ort/spark/conf/hive-site.xml\n",
      "2023-11-18T21:59:24,915 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.wm.default.pool.size does not exist\n",
      "2023-11-18T21:59:24,915 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.task.scheduler.preempt.independent does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.output.format.arrow does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.tez.llap.min.reducer.per.executor does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.arrow.root.allocator.limit does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.use.checked.expressions does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.tez.dynamic.semijoin.reduction.for.mapjoin does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.complex.types.enabled does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.wm.worker.threads does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.repl.partitions.dump.parallelism does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.uri.selection does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.strict.checks.no.partition.filter does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.tez.dynamic.semijoin.reduction.for.dpp.factor does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.filter.in.min.ratio does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.client.cache.initial.capacity does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.ndv.estimate.percent does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.webui.cors.allowed.methods does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.optimize.joinreducededuplication does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.client.cache.enabled does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.fetch.bitvector does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.disable.unsafe.external.table.operations does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.materializedview.rewriting.incremental does not exist\n",
      "2023-11-18T21:59:24,916 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.materializedviews.registry.impl does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.event.db.notification.api.auth does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.exec.orc.delta.streaming.optimizations.enabled does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.ndv.algo does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.spark.job.max.tasks does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.msck.repair.batch.max.retries does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.prewarm.spark.timeout does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.optimize.update.table.properties.from.serde.list does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.plugin.client.num.threads does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.test.bucketcodec.version does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.reexecution.enabled does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.materializedview.rewriting.time.window does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.reexecution.stats.cache.batch.size does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.webui.cors.allowed.headers does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.join.inner.residual does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.active.passive.ha.enable does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.trace.always.dump does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.reexecution.stats.persist.scope does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.mm.allow.originals does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.compactor.compact.insert.only does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.txn.xlock.iow does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.spark.rsc.conf.list does not exist\n",
      "2023-11-18T21:59:24,917 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.cache.defaultfs.only.native.fileid does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.spark.optimize.shuffle.serde does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.testing.remove.logs does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.distcp.privileged.doAs does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.strict.checks.orderby.no.limit does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.client.cache.expiry.time does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.allocator.defrag.headroom does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.notification.event.consumers does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.input.format.supports.enabled does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.client.cache.max.capacity does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.repl.dumpdir.clean.freq does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.spark.use.ts.stats.for.mapjoin does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.repl.dump.include.acid.tables does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.webui.use.pam does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.reexecution.max.count does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.share.object.pools does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.optimize.update.table.properties.from.serde does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.service.metrics.codahale.reporter.classes does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.tez.session.events.print.summary does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.vrb.queue.limit.base does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.mm.avoid.s3.globstatus does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.repl.replica.functions.root.dir does not exist\n",
      "2023-11-18T21:59:24,918 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.results.cache.max.entry.lifetime does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.limit.connections.per.user does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.thrift.http.compression.enabled does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.execution.ptf.enabled does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.optimize.shared.work.extended does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.row.identifier.enabled does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.reexecution.always.collect.operator.stats does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.repl.dumpdir.ttl does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.local.time.zone does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.tez.wm.am.registry.timeout does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.active.passive.ha.registry.namespace does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.create.as.insert.only does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.mapjoin.memory.oversubscribe.factor does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.arrow.batch.size does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.notification.sequence.lock.retry.sleep.interval does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.repl.approx.max.load.tasks does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.results.cache.enabled does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.legacy.schema.for.all.serdes does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.tez.dag.status.check.interval does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.druid.bitmap.type does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.spark.dynamic.partition.pruning.map.join.only does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.memory.oversubscription.max.executors.per.query does not exist\n",
      "2023-11-18T21:59:24,919 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.trace.size does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.plugin.rpc.num.handlers does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.wm.allow.any.pool.via.jdbc does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.groupby.complex.types.enabled does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.avro.timestamp.skip.conversion does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.results.cache.nontransactional.tables.enabled does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.correlated.multi.key.joins does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.db.type does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.streaming.auto.flush.check.interval.size does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.zookeeper.connection.timeout does not exist\n",
      "2023-11-18T21:59:24,920 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.reexecution.strategies does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.limit.connections.per.user.ipaddress does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.mapjoin.memory.monitor.check.interval does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.optimize.shared.work does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.estimate does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.allocator.discard.method does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.tez.cartesian-product.enabled does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.notification.sequence.lock.max.retries does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.heap.memory.monitor.usage.threshold does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.privilege.synchronizer.interval does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.adaptor.suppress.evaluate.exceptions does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.materializedview.rebuild.incremental does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.results.cache.max.entry.size does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.spark.stage.max.tasks does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.testing.short.logs does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.streaming.auto.flush.enabled does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.spark.explain.user does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.describe.partitionedtable.ignore.stats does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.operation.log.cleanup.delay does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.repl.dump.metadata.only does not exist\n",
      "2023-11-18T21:59:24,921 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.optimize.countdistinct does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.auto.convert.join.shuffle.max.size does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.plugin.acl does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.schema.info.class does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.tez.queue.access.check does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.external.splits.temp.table.storage.format does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.row.wrapper.enabled does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.constraint.notnull.enforce does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.cli.print.escape.crlf does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.trigger.validation.interval does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.webui.cors.allowed.origins does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.limit.connections.per.ipaddress does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.external.splits.order.by.force.single.split does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.metastore.client.cache.stats.enabled does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.notification.event.poll.interval does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.transactional.concatenate.noblock does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.materializedview.rewriting.strategy does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.if.expr.mode does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.exim.test.mode does not exist\n",
      "2023-11-18T21:59:24,922 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.results.cache.directory does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.results.cache.wait.for.pending.results does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.remove.orderby.in.subquery does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.tez.bmj.use.subcache does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.vrb.queue.limit.min does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.wm.pool.metrics does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.repl.add.raw.reserved.namespace does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.resource.use.hdfs.location does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.num.nulls.estimate.percent does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.acid does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.zk.sm.session.timeout does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.ptf.max.memory.buffering.batch.count does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.task.scheduler.am.registry does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.druid.overlord.address.default does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.optimize.remove.sq_count_check does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.server2.webui.enable.cors does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.vectorized.row.serde.inputformat.excludes does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.reexecution.stats.cache.size does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.combine.equivalent.work.optimization does not exist\n",
      "2023-11-18T21:59:24,923 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.lock.query.string.max.length does not exist\n",
      "2023-11-18T21:59:24,924 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.llap.io.track.cache.usage does not exist\n",
      "2023-11-18T21:59:24,924 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.use.orc.codec.pool does not exist\n",
      "2023-11-18T21:59:24,924 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.query.results.cache.max.size does not exist\n",
      "2023-11-18T21:59:24,924 WARN [Thread-4] org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.repl.bootstrap.dump.open.txn.timeout does not exist\n",
      "2023-11-18T21:59:25,215 INFO [Thread-4] hive.metastore - Trying to connect to metastore with URI thrift://localhost:9083\n",
      "2023-11-18T21:59:25,293 INFO [Thread-4] hive.metastore - Opened a connection to metastore, current connections: 1\n",
      "2023-11-18T21:59:25,361 INFO [Thread-4] hive.metastore - Connected to metastore.\n",
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "| big_data|\n",
      "| datalake|\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crear una nueva base de datos en Hive\n",
    "spark.sql(\"CREATE DATABASE if not exists datalake\")\n",
    "\n",
    "# Listar bases de datos para verificar\n",
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a592790-cced-4862-9dc6-d96eca87b58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use datalake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef92856f-6246-4816-8e9f-95df83c675cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-18T22:07:35,046 INFO [Thread-4] org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAccessController - Created SQLStdHiveAccessController for session context : HiveAuthzSessionContext [sessionString=349f44e8-f284-435b-b59b-f9608c9f8ff9, clientType=HIVECLI]\n",
      "2023-11-18T22:07:35,051 WARN [Thread-4] org.apache.hadoop.hive.ql.session.SessionState - METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "2023-11-18T22:07:35,051 INFO [Thread-4] hive.metastore - Mestastore configuration hive.metastore.filter.hook changed from org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl to org.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook\n",
      "2023-11-18T22:07:35,058 INFO [Thread-4] hive.metastore - Closed a connection to metastore, current connections: 0\n",
      "2023-11-18T22:07:35,060 INFO [Thread-4] hive.metastore - Trying to connect to metastore with URI thrift://localhost:9083\n",
      "2023-11-18T22:07:35,061 INFO [Thread-4] hive.metastore - Opened a connection to metastore, current connections: 1\n",
      "2023-11-18T22:07:35,078 INFO [Thread-4] hive.metastore - Connected to metastore.\n",
      "2023-11-18T22:07:35,393 INFO [Thread-4] hive.metastore - Trying to connect to metastore with URI thrift://localhost:9083\n",
      "2023-11-18T22:07:35,394 INFO [Thread-4] hive.metastore - Opened a connection to metastore, current connections: 2\n",
      "2023-11-18T22:07:35,399 INFO [Thread-4] hive.metastore - Connected to metastore.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE usuarios (\n",
    "    id_usuario STRING,\n",
    "    nombre STRING,\n",
    "    apellido STRING,\n",
    "    email STRING,\n",
    "    sexo  STRING,\n",
    "    pais STRING,\n",
    "    actividad STRING,\n",
    "    subscripcion STRING,\n",
    "    fecha_subs DATE,\n",
    "    recha_renov DATE, \n",
    "    ultimo_pago DATE\n",
    ")\n",
    "STORED AS PARQUET\n",
    "LOCATION '/datalake/clean/usuarios';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3786bb50-079a-4cc9-ac47-2742caa3c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actividades = spark.read.parquet(\"/datalake/clean/actividades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7514eb9-de75-4865-9ac8-55b0919f20e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_actividad: string (nullable = true)\n",
      " |-- id_usuario: string (nullable = true)\n",
      " |-- id_dispositivo: string (nullable = true)\n",
      " |-- id_plan: string (nullable = true)\n",
      " |-- pais: string (nullable = true)\n",
      " |-- longitud: float (nullable = true)\n",
      " |-- latitud: float (nullable = true)\n",
      " |-- duracion: integer (nullable = true)\n",
      " |-- fecha_hora: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_actividades.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40694f7-1234-496c-977a-dbdff15dbc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------+--------------------+----------+--------------+-------------+------------+----------+-----------+-----------+\n",
      "|          id_usuario|     nombre|     apellido|               email|      sexo|          pais|    actividad|subscripcion|fecha_subs|recha_renov|ultimo_pago|\n",
      "+--------------------+-----------+-------------+--------------------+----------+--------------+-------------+------------+----------+-----------+-----------+\n",
      "|9efa1289-5256-49c...|      Elise|       Austen|  eausten1@unblog.fr|    Female|        Brazil|     natacion|      basica|2022-12-13|       null| 2022-12-25|\n",
      "|b4d30551-59cb-45b...|   Rochella|      Davidof|rdavidof2@timeson...|Non-binary|        Russia|personalizado|      basica|2023-04-22|       null| 2023-07-20|\n",
      "|effbcd55-e394-487...|Worthington|  Sherringham|wsherringham5@tut...|      Male|     Indonesia|personalizado|       anual|2023-03-26|       null| 2023-10-27|\n",
      "|fc621f46-e0ef-4ad...|    Camella|       Crooke|ccrooke6@newsvine...|  Bigender|        Russia|         yoga|      basica|2022-12-17|       null| 2023-10-17|\n",
      "|5cc10861-3ddd-467...|   Anatollo|        Jeggo|  ajeggo7@oracle.com|      null|          Cuba|         yoga|      basica|2023-09-20|       null| 2023-01-22|\n",
      "|1ee35bd7-2a17-4a8...|       Dore|       Strong|   dstrong8@ehow.com|    Female|         China|      basquet|       anual|2023-05-01|       null| 2023-08-21|\n",
      "|969d8cac-57dc-4e6...|      Royce|MacGillicuddy|rmacgillicuddyb@h...|      Male|        Brazil|      basquet|      basica|2022-12-24|       null| 2023-10-16|\n",
      "|4df73c8b-4928-4cf...|      Dredi|     Gritland|dgritlande@friend...|    Female|       Bolivia|       futbol|      basica|2023-01-05|       null| 2023-04-02|\n",
      "|ec0773cb-7e77-4bb...|      Janel|    Kilgallen|jkilgallenf@behan...|    Female|       Vietnam|         null|      basica|2022-12-04|       null| 2023-09-09|\n",
      "|077cc415-56b7-4e3...|    Shepard|   McCullouch|smccullouchh@icio.us|      null|        Canada|         yoga|       anual|2023-04-27|       null| 2023-10-26|\n",
      "|6073dae1-6fca-4a3...|   Berenice|       Fudger|    bfudgerj@nps.gov|    Female|         China|     natacion|      basica|2023-08-05|       null| 2023-08-23|\n",
      "|634264b8-26d7-4cd...|       Hedy|    Cotterill|hcotterillk@oakle...|   Agender|         China|         yoga|      basica|2023-06-08|       null| 2023-06-28|\n",
      "|91971f49-2484-444...|    Gaylene|       Fasham|     gfashaml@go.com|    Female|        Brazil|     triatlon|       anual|2023-04-17|       null| 2023-04-10|\n",
      "|0075f59b-4ec7-49b...|      Becca|      Schwand|bschwandm@deviant...|  Bigender|        Russia|personalizado|       anual|2023-01-27|       null| 2022-12-15|\n",
      "|dab0b8a3-0fd7-499...|      Nicol|       Whyard|nwhyardn@newsvine...|      Male|     Indonesia|       futbol|      basica|2023-06-07|       null| 2023-03-31|\n",
      "|60e15872-eddb-410...|     Cherry|    Bettinson|cbettinsono@media...|  Bigender|         China|       futbol|       anual|2023-03-14|       null| 2023-02-16|\n",
      "|b54cc38b-9916-4b9...|      Ashia|       Tramel|atramelp@omniture...|    Female|      Malaysia|     triatlon|      basica|2023-06-25|       null| 2023-05-31|\n",
      "|bc1cb69e-5aa0-496...|    Darnell|      Tumpane|dtumpanes@over-bl...|      Male|        Serbia|        tenis|      basica|2023-02-07|       null| 2023-01-06|\n",
      "|6b063767-94ad-4b5...|     Burton|     Priscott|bpriscottu@reverb...|      Male|       Morocco|       futbol|       anual|2023-08-05|       null| 2023-11-12|\n",
      "|35d25e54-e08b-475...|     Carlie|        Skyme|cskymew@rakuten.c...|      Male|United Kingdom|      basquet|       anual|2022-12-01|       null| 2023-03-21|\n",
      "+--------------------+-----------+-------------+--------------------+----------+--------------+-------------+------------+----------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select *\n",
    "from usuarios\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2408727-6a47-4d4c-bcfc-0a52be4aa282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE actividades (\n",
    "    id_actividad STRING,\n",
    "    id_usuario STRING,\n",
    "    id_dispositivo STRING,\n",
    "    id_plan STRING,\n",
    "    pais STRING,\n",
    "    longitud FLOAT,\n",
    "    latitud FLOAT,\n",
    "    duracion INT,\n",
    "    fecha_hora TIMESTAMP\n",
    ")\n",
    "STORED AS PARQUET\n",
    "LOCATION '/datalake/clean/actividades';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a2845b6-de0f-499d-958a-7316750ddb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------+--------+--------+--------+-------------------+\n",
      "|        id_actividad|          id_usuario|      id_dispositivo|             id_plan|          pais|longitud| latitud|duracion|         fecha_hora|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------+--------+--------+--------+-------------------+\n",
      "|d2b9f5a4-e457-406...|9efa1289-5256-49c...|5f6742cf-0cc3-499...|1a257404-2741-4d5...|        Brazil|-47.9247|-38.5258|       1|2023-07-08 06:10:00|\n",
      "|742ceebe-7cbd-42a...|b4d30551-59cb-45b...|9c9d7ede-4915-4fd...|296f1010-fd8b-4fe...|        Russia|100.6432| 60.0272|       2|2023-03-01 02:16:00|\n",
      "|f079c279-1249-40e...|effbcd55-e394-487...|af1e4b22-9836-4ff...|d3c2f38b-249f-40c...|     Indonesia|112.6225| -7.7611|       3|2023-09-17 07:09:00|\n",
      "|b8db20aa-9915-426...|fc621f46-e0ef-4ad...|5d5aa38b-9e5e-412...|b206f2a3-5ddd-47a...|        Russia|100.6432| 60.0272|       2|2023-05-27 10:45:00|\n",
      "|59b61169-ecde-498...|5cc10861-3ddd-467...|39e8db1f-0258-459...|147cd3b7-c8c6-4b6...|          Cuba|-78.4163| 22.2258|       1|2023-08-24 06:49:00|\n",
      "|8ea971d8-bc3e-44c...|1ee35bd7-2a17-4a8...|6188ae01-946b-40e...|0c384ba2-f2c6-4ca...|         China|106.3456| 35.3371|       1|2023-05-18 00:35:00|\n",
      "|f0c4dc60-3cf3-4f9...|969d8cac-57dc-4e6...|0b8d0acd-7391-449...|bd1a59f8-8928-4e7...|        Brazil|-47.9247|-38.5258|       1|2023-05-14 09:20:00|\n",
      "|32bf0c7b-f21a-44b...|4df73c8b-4928-4cf...|cac63327-f1b8-4ba...|952079f9-5b2e-4fe...|       Bolivia|-63.2369|-17.4052|       3|2022-12-08 01:13:00|\n",
      "|d25130a0-8a5d-4d4...|ec0773cb-7e77-4bb...|a8ec5dc7-b977-432...|2c829d9d-fe05-41c...|       Vietnam|105.7858| 17.0296|       3|2023-10-29 14:26:00|\n",
      "|c1cc1ec2-c886-401...|077cc415-56b7-4e3...|5f6742cf-0cc3-499...|1e2d7203-4d5d-4bc...|        Canada|-102.234|  54.263|       3|2023-08-23 02:31:00|\n",
      "|bbf9ea4b-92da-4d5...|6073dae1-6fca-4a3...|9c9d7ede-4915-4fd...|5e91d1d7-7a6d-45c...|         China|106.3456| 35.3371|       1|2023-02-28 05:34:00|\n",
      "|b17e5626-7322-41f...|634264b8-26d7-4cd...|af1e4b22-9836-4ff...|9486001c-d371-445...|         China|106.3456| 35.3371|       2|2023-10-16 02:16:00|\n",
      "|85973b7a-ccbc-468...|91971f49-2484-444...|5d5aa38b-9e5e-412...|ae8ad1f2-6948-483...|        Brazil|-47.9247|-38.5258|       2|2023-04-18 14:43:00|\n",
      "|450dfea1-0901-403...|0075f59b-4ec7-49b...|39e8db1f-0258-459...|ad24d4a2-6d6a-4fd...|        Russia|100.6432| 60.0272|       1|2023-04-04 02:09:00|\n",
      "|403e65e0-fb25-4c9...|dab0b8a3-0fd7-499...|6188ae01-946b-40e...|45d226cb-97e2-468...|     Indonesia|112.6225| -7.7611|       2|2023-06-14 20:30:00|\n",
      "|2e97bcf6-f08d-438...|60e15872-eddb-410...|0b8d0acd-7391-449...|6d2e59c2-d835-4d0...|         China|106.3456| 35.3371|       3|2023-03-14 23:00:00|\n",
      "|97a271fd-5536-454...|b54cc38b-9916-4b9...|cac63327-f1b8-4ba...|3daa65e4-958b-4eb...|      Malaysia|103.3027|  4.6123|       3|2023-09-27 11:21:00|\n",
      "|1464ffdb-52a1-4ca...|bc1cb69e-5aa0-496...|a8ec5dc7-b977-432...|a862dc28-bd36-457...|        Serbia| 21.0284| 44.0241|       3|2023-08-03 23:13:00|\n",
      "|a0aef17f-da73-46f...|6b063767-94ad-4b5...|5f6742cf-0cc3-499...|03469e27-a2dd-436...|       Morocco| -7.5938|  33.685|       3|2023-01-28 15:36:00|\n",
      "|b3b399f8-ded7-4ea...|35d25e54-e08b-475...|9c9d7ede-4915-4fd...|cd4d63b1-f532-45d...|United Kingdom| -0.1257| 51.5086|       3|2023-01-26 21:32:00|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------+--------+--------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from actividades\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57c40ce2-5c3b-4eae-861d-09fa5bfe7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actividades_eventos = spark.read.parquet(\"/datalake/clean/actividades_eventos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac291087-693d-4db7-b4a3-7ae7fb31d8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_sensor: string (nullable = true)\n",
      " |-- pulse_rate: integer (nullable = true)\n",
      " |-- id_actividad: string (nullable = true)\n",
      " |-- longitud: float (nullable = true)\n",
      " |-- latitud: float (nullable = true)\n",
      " |-- fecha_hora: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_actividades_eventos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba33006b-346e-4a76-ab44-96414ea66e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE actividades_eventos (\n",
    "    id_sensor STRING,\n",
    "    pulse_rate integer,\n",
    "    id_actividad STRING,\n",
    "    longitud FLOAT,\n",
    "    latitud FLOAT,\n",
    "    fecha_hora TIMESTAMP\n",
    ")\n",
    "STORED AS PARQUET\n",
    "LOCATION '/datalake/clean/actividades_eventos';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "252ac101-d4ae-4ef9-a971-3a5b03790ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------+--------+-------------------+\n",
      "|           id_sensor|pulse_rate|        id_actividad|longitud| latitud|         fecha_hora|\n",
      "+--------------------+----------+--------------------+--------+--------+-------------------+\n",
      "|853dc9e4-6094-451...|       173|d2b9f5a4-e457-406...|-47.9247|-38.5258|2023-07-08 06:10:00|\n",
      "|278b2f82-087a-469...|       128|742ceebe-7cbd-42a...|100.6432| 60.0272|2023-03-01 02:16:00|\n",
      "|ea0b5fad-ff1d-491...|       148|f079c279-1249-40e...|112.6225| -7.7611|2023-09-17 07:09:00|\n",
      "|f6f4ad28-30e2-4c8...|       110|b8db20aa-9915-426...|100.6432| 60.0272|2023-05-27 10:45:00|\n",
      "|e63edcf3-eca8-412...|       170|59b61169-ecde-498...|-78.4163| 22.2258|2023-08-24 06:49:00|\n",
      "|bab58192-fc85-49c...|        42|8ea971d8-bc3e-44c...|106.3456| 35.3371|2023-05-18 00:35:00|\n",
      "|cafd29e6-3782-4fa...|       197|f0c4dc60-3cf3-4f9...|-47.9247|-38.5258|2023-05-14 09:20:00|\n",
      "|ce9ed08c-ccdc-48d...|       198|32bf0c7b-f21a-44b...|-63.2369|-17.4052|2022-12-08 01:13:00|\n",
      "|999d5a48-6543-4bd...|       166|d25130a0-8a5d-4d4...|105.7858| 17.0296|2023-10-29 14:26:00|\n",
      "|833ffb9f-2bcd-442...|       171|c1cc1ec2-c886-401...|-102.234|  54.263|2023-08-23 02:31:00|\n",
      "|33cd50a4-13de-4c9...|        93|bbf9ea4b-92da-4d5...|106.3456| 35.3371|2023-02-28 05:34:00|\n",
      "|0fea6730-98b8-4ae...|        64|b17e5626-7322-41f...|106.3456| 35.3371|2023-10-16 02:16:00|\n",
      "|8099ae7b-7b54-4e5...|        40|85973b7a-ccbc-468...|-47.9247|-38.5258|2023-04-18 14:43:00|\n",
      "|cacba4b7-580d-40b...|       109|450dfea1-0901-403...|100.6432| 60.0272|2023-04-04 02:09:00|\n",
      "|280b39f5-153d-4c9...|       166|403e65e0-fb25-4c9...|112.6225| -7.7611|2023-06-14 20:30:00|\n",
      "|9293d8f3-cf73-488...|       138|2e97bcf6-f08d-438...|106.3456| 35.3371|2023-03-14 23:00:00|\n",
      "|39bf036f-0d81-4ff...|       144|97a271fd-5536-454...|103.3027|  4.6123|2023-09-27 11:21:00|\n",
      "|f709fcfb-7a2b-43b...|       197|1464ffdb-52a1-4ca...| 21.0284| 44.0241|2023-08-03 23:13:00|\n",
      "|ab68d4ad-5c8a-456...|        62|a0aef17f-da73-46f...| -7.5938|  33.685|2023-01-28 15:36:00|\n",
      "|0ae925b0-bb7d-4c8...|       122|b3b399f8-ded7-4ea...| -0.1257| 51.5086|2023-01-26 21:32:00|\n",
      "+--------------------+----------+--------------------+--------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from actividades_eventos\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "888fded8-9fdf-493a-bef4-5e35ef1f5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_plan: string (nullable = true)\n",
      " |-- id_usuario: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- plan_duracion: float (nullable = true)\n",
      " |-- instructions: string (nullable = true)\n",
      " |-- objectivo: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_planes = spark.read.parquet(\"/datalake/clean/planes_de_entrenamiento\")\n",
    "df_planes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6d90fbd-0216-4813-8259-62b115e356b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE planes_de_entrenamiento (\n",
    "    id_plan STRING,\n",
    "    id_usuario STRING,\n",
    "    tipo STRING,\n",
    "    plan_duracion FLOAT,\n",
    "    instructions STRING,\n",
    "    objectivo STRING\n",
    ")\n",
    "STORED AS PARQUET\n",
    "LOCATION '/datalake/clean/planes_de_entrenamiento';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcfb08bf-e8df-4e5d-be90-2fbb54586eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+-------------+--------------------+--------------------+\n",
      "|id_plan|          id_usuario|            tipo|plan_duracion|        instructions|           objectivo|\n",
      "+-------+--------------------+----------------+-------------+--------------------+--------------------+\n",
      "|      1|9efa1289-5256-49c...|   media-maraton|         1.63|Lorem ipsum dolor...|Maecenas leo odio...|\n",
      "|      2|b4d30551-59cb-45b...|            hiit|         1.73|Nulla ut erat id ...|Duis bibendum. Mo...|\n",
      "|      3|effbcd55-e394-487...|condicionamiento|          1.3|Proin leo odio po...|Donec diam neque,...|\n",
      "|      4|fc621f46-e0ef-4ad...|            otro|         1.25|Cum sociis natoqu...|Quisque id justo ...|\n",
      "|      5|5cc10861-3ddd-467...|            hiit|         1.67|Duis consequat du...|Maecenas leo odio...|\n",
      "|      6|1ee35bd7-2a17-4a8...|        triatlon|          1.0|Cras non velit ne...|Mauris enim leo, ...|\n",
      "|      7|969d8cac-57dc-4e6...|            otro|         1.56|Mauris enim leo r...|Integer ac leo. P...|\n",
      "|      8|4df73c8b-4928-4cf...|            otro|         1.27|Duis bibendum fel...|Cum sociis natoqu...|\n",
      "|      9|ec0773cb-7e77-4bb...|   bajar de peso|         1.37|Curabitur in libe...|Praesent id massa...|\n",
      "|     10|077cc415-56b7-4e3...|   bajar de peso|         0.58|Fusce consequat. ...|Curabitur gravida...|\n",
      "|     11|6073dae1-6fca-4a3...|disminuir stress|          1.1|Maecenas ut massa...|Cum sociis natoqu...|\n",
      "|     12|634264b8-26d7-4cd...|   bajar de peso|         1.37|Mauris enim leo r...|Curabitur in libe...|\n",
      "|     13|91971f49-2484-444...|            otro|          1.4|Vestibulum ac est...|Sed sagittis. Nam...|\n",
      "|     14|0075f59b-4ec7-49b...|   bajar de peso|         1.85|Vestibulum ac est...|Proin leo odio, p...|\n",
      "|     15|dab0b8a3-0fd7-499...|disminuir stress|         0.82|Maecenas tristiqu...|Nullam porttitor ...|\n",
      "|     16|60e15872-eddb-410...|disminuir stress|         0.54|Proin interdum ma...|Morbi non lectus....|\n",
      "|     17|b54cc38b-9916-4b9...|   media-maraton|         1.74|Cras non velit ne...|Mauris enim leo, ...|\n",
      "|     18|bc1cb69e-5aa0-496...|condicionamiento|         0.51|Proin interdum ma...|In quis justo. Ma...|\n",
      "|     19|6b063767-94ad-4b5...|        triatlon|         1.98|Suspendisse poten...|Proin interdum ma...|\n",
      "|     20|35d25e54-e08b-475...|   bajar de peso|         1.12|Sed sagittis. Nam...|Vestibulum quam s...|\n",
      "+-------+--------------------+----------------+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from planes_de_entrenamiento\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cbdb2da-19a4-41cd-9c37-26c074aeb935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id_dispositivo: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- operating_system: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_planes = spark.read.parquet(\"/datalake/clean/dispositivos\")\n",
    "df_planes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1031cf80-24e8-44d3-83d2-2954c3cc16a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE dispositivos (\n",
    "    id_dispositivo STRING,\n",
    "    model STRING,\n",
    "    brand STRING,\n",
    "    operating_system STRING\n",
    ")\n",
    "STORED AS PARQUET\n",
    "LOCATION '/datalake/clean/dispositivos';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24094ee9-6940-4c19-a696-ba3b01a3ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-------+----------------+\n",
      "|      id_dispositivo|           model|  brand|operating_system|\n",
      "+--------------------+----------------+-------+----------------+\n",
      "|5f6742cf-0cc3-499...|   iPhone 12 Pro|  Apple|             iOS|\n",
      "|9c9d7ede-4915-4fd...|         Pixel 5| Google|         Android|\n",
      "|af1e4b22-9836-4ff...|    Xperia 1 III|   Sony|         Android|\n",
      "|5d5aa38b-9e5e-412...|     Find X3 Pro|   Oppo|         Android|\n",
      "|39e8db1f-0258-459...|          Velvet|     LG|         Android|\n",
      "|6188ae01-946b-40e...|         X60 Pro|   Vivo|         Android|\n",
      "|0b8d0acd-7391-449...|           9 Pro|OnePlus|         Android|\n",
      "|cac63327-f1b8-4ba...|Galaxy S21 Ultra|Samsung|         Android|\n",
      "|a8ec5dc7-b977-432...|           Mi 11| Xiaomi|         Android|\n",
      "+--------------------+----------------+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from dispositivos\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
